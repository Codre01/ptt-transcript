# React Native Assignment

# Overview
Build a small Expo (React Native, TypeScript) app that implements a **press-to-talk (PTT)** voice capture flow. The app records audio locally, then—after a simulated network delay—receives a **transcript** (no audio playback) from a **stubbed** **`VoiceApi`** that returns **timed Promises**. The app must clearly show the states **Listening → Processing → Result**, support a **clarification** turn when required, and handle **errors** gracefully. No backend or NestJS work is required.

**Deadline:** November 2nd 23:59 CET
**Platform:** Expo (managed workflow) + TypeScript
# What you’ll build
## Core user flow
1. **Hold to talk**
    *   While the button is held: start recording and show a capture sheet/overlay.
    *   On release: stop recording, **save the audio file locally**, and move to **Processing**.
2. **Processing (simulated network)**
    *   Call a **stubbed** **`VoiceApi`** that resolves after a delay (1000 ms by default) and returns a **transcript string**.
    *   Show **Processing…** UI until the result arrives.
3. **Result (Transcript)**
    *   Display the transcript prominently in the UI.
    *   If the API asks for a **clarification**, show the prompt and return the user to **PTT** to provide the follow-up utterance. The second utterance should produce a normal transcript result.
4. **Cancel**
    *   While recording, a **Cancel** action must discard the current recording and return to Idle.
> Note: **No TTS playback** is required in this assignment.
## Scope constraints (locked)
*   **Transcript only:** The AI “response” is text (no audio).
*   **Mocking strategy:** A **stubbed** **`VoiceApi`** **class** returning **timed Promises** (no MSW/Apollo; no real network).
*   **Clarification flow:** **Required** (at least one scenario).
*   **Error handling:** **Required** (network-like failure and generic server-like failure).
*   **Repeat / playback:** **Not required.**
*   **Permissions:** **Microphone permission only.**
*   **Cross-platform media specifics:** Not required to vary by OS; keep it simple and working on both simulators/emulators.
*   **Metrics/latency logs:** Not required.
## UI & State requirements
### Visual states (must be obvious)
*   **Idle** — PTT button visible; last transcript(s) visible in a simple list or card.
*   **Listening** — Shown only while the user holds the button. Include a minimal animation (e.g., pulsing dot or bars).
*   **Processing** — After release; shows that the app is transcribing/thinking.
*   **Result** — Shows the returned transcript text.
*   **Error** — Shows a non-technical message and a way to try again.
### Recording UI
*   **PTT button** (hold to record; release to stop).
*   **Capture overlay/sheet** during Listening with:
    *   **Timer or subtle animation** indicating capture is live.
    *   **Cancel** button to discard the current recording and return to Idle.
### Clarification UI
*   If the API returns a clarification prompt (e.g., “What time should I set it for?”), show it as a small banner or inline card.
*   The next PTT utterance should **complete the turn** and yield a normal transcript result.
### Error UX
*   Simulate at least two cases via the stub/fixtures:
    *   **Network-like failure** (reject Promise with a “network” error)
    *   **Server-like failure** (reject with an error object containing a `code` and `message`)
*   In both cases:
    *   Return to a **safe, interactive state** (Idle).
    *   Show a user-friendly message (e.g., “Couldn’t process that. Please try again.”).
    *   Preserve any **prior** transcripts on screen.
## Audio & file behavior
*   Request **microphone permission** just-in-time on first use; handle denial gracefully (explain and provide a retry path).
*   Use Expo-friendly recording (e.g., `expo-av`) to capture audio while the button is held.
*   On release, **stop and save** the recording to a temporary local file (e.g., `FileSystem.cacheDirectory`).
*   Clean up obviously stale temp files on app start or after successful processing (basic hygiene; don’t over-engineer).
# The mocked API (stubbed class)
## Interface (you can adjust names, but keep the intent)

```typescript
// types.ts
export type ProcessVoiceInput = {
  audioUri: string;     // local file path of the recorded audio
  mimeType: string;     // e.g., "audio/m4a" or similar
  clientTs: string;     // ISO date string from client
  context?: Record<string, unknown>; // optional, for clarification
};

export type ProcessVoiceResult =
  | {
      kind: "ok";
      transcript: string;
    }
  | {
      kind: "clarification";
      prompt: string; // e.g., "What time should I set it for?"
    };

export type ProcessVoiceError = {
  kind: "error";
  code: "NETWORK" | "SERVER";
  message: string; // user-readable
};

// VoiceApi.ts
export interface VoiceApi {
  processVoice(input: ProcessVoiceInput): Promise<ProcessVoiceResult>;
}

export class StubVoiceApi implements VoiceApi {
  constructor(private opts?: { delayMs?: number; scenario?: "success" | "clarify" | "networkError" | "serverError" }) {}

  async processVoice(input: ProcessVoiceInput): Promise<ProcessVoiceResult> {
    const delay = this.opts?.delayMs ?? 1000;
    await new Promise((r) => setTimeout(r, delay));

    switch (this.opts?.scenario) {
      case "clarify":
        return { kind: "clarification", prompt: "What time should I set it for?" };
      case "networkError":
        throw { kind: "error", code: "NETWORK", message: "Network error. Please try again." };
      case "serverError":
        throw { kind: "error", code: "SERVER", message: "Something went wrong. Please try again." };
      case "success":
      default:
        return { kind: "ok", transcript: "Added ‘milk’ to your shopping list." };
    }
  }
}
```

## Scenario switching
*   Provide a simple way to switch scenarios **at runtime** (e.g., a small developer toggle in the UI or a segmented control):
    *   **Success** (returns `kind: "ok"` with a transcript)
    *   **Clarification** (returns `kind: "clarification"`; the very next PTT call should then return a normal success—your choice how you implement that)
    *   **Network error**
    *   **Server error**
> The app should behave identically regardless of scenario: same states, clear messages, never crashes.
# Technical requirements
*   **Stack:** Expo (managed) + React Native + TypeScript.
*   **Recording:** `expo-av` or equivalent Expo-compatible API.
*   **State management:** your choice (React state/hooks, Zustand, Redux, etc.)—keep it simple and clear.
*   **Structure:** Separate concerns into at least:
    *   `AudioService` (start/stop, permissions, file cleanup)
    *   `VoiceApi` (the stub above)
    *   UI components (PTT button, overlay, transcript list, error/clarification banners)
*   **No secrets** or external services; everything runs locally.
*   **Accessibility:** Buttons should be labeled (`accessibilityLabel`) and large enough to press in the simulator.
# Deliverables
1. **GitHub repository** with an `/app` folder (no server code required).
2. **README** containing:
    *   Prereqs and how to run on iOS simulator and Android emulator.
    *   Brief architecture overview (how `AudioService` and `VoiceApi` interact; your state diagram or list of states).
    *   How to toggle **Success / Clarification / Network error / Server error** scenarios.
    *   Notes on audio file lifecycle (where you store them and how you clean up).
3. **Short screen recording (≤3 minutes)** demonstrating:
    *   Happy path: hold-to-record → Processing → transcript shown.
    *   Clarification path: app asks a clarifying question → user records a follow-up → transcript shown.
    *   Error path: show each error type once and recovery back to Idle.
    *   Cancel during recording.
4. (Optional but appreciated) **1–2 small tests** for your PTT component or state reducer.
# Acceptance criteria (what “done” looks like)
*   **PTT & states**
    *   Hold to record; visible **Listening** state while pressed.
    *   On release: **Processing** state, then transcript displayed as **Result**.
    *   **Cancel** discards the in-progress recording and returns to Idle.
*   **Recording & files**
    *   Microphone permission requested just-in-time; denial handled gracefully.
    *   Audio saved to a **local file** on release; obvious cleanup of old temp files.
*   **Clarification**
    *   At least one scenario where the app presents a prompt and requires a follow-up PTT to complete.
*   **Errors**
    *   **Network-like** and **Server-like** failures produce friendly messages and a safe recovery to Idle.
    *   Previous successful transcripts remain visible; no crashes; no unhandled promise rejections.
*   **Code quality**
    *   TypeScript types for API and state.
    *   Clear separation of responsibilities (audio vs. API vs. UI).
    *   Simple, readable components and minimal prop drilling (hooks/services where appropriate).
*   **DX & docs**
    *   App runs with one or two commands.
    *   README explains scenarios and any assumptions.
# Evaluation rubric (100 pts)
*   **Product fit & UX clarity (20):** States are obvious; PTT feels natural; cancel works; transcript display is clean.
*   **Audio capture & file handling (20):** Recording lifecycle is correct; files saved/cleaned; permission flow is solid.
*   **API boundary & mock quality (20):** `VoiceApi` stub is well-typed, timed, and easy to toggle; UI doesn’t depend on internal stub details.
*   **State management & clarity (15):** Idle/Listening/Processing/Result/Error/Clarification are unambiguous; no race conditions.
*   **Error handling & resilience (15):** Friendly messages; safe recovery; prior results persist; no crashes.
*   **Documentation & handoff (10):** README is complete; video shows all flows; repo structure is tidy.
# Submission checklist (what to send us)
*   ✅ GitHub repo link
*   ✅ README with run instructions + scenario toggles
*   ✅ ≤3-minute demo video covering happy, clarification, error, and cancel
*   ✅ (Optional) brief comments on trade-offs you made (e.g., file formats, state approach)
## Notes & tips (non-binding)
*   A subtle animation (pulsing mic, bars) during **Listening** makes the demo feel polished.
*   Keep the UI minimal—one primary screen is enough.
*   Don’t overcomplicate audio formats; a single common format (e.g., m4a) is fine in Expo.

That’s it—you have everything you need without backend work.